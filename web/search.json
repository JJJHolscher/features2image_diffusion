[
  {
    "objectID": "image-gen-on-edited-features.html",
    "href": "image-gen-on-edited-features.html",
    "title": "",
    "section": "",
    "text": "%cd ..\n\n/home/jo3/p/features2image_diffusion\n\n\n/home/jo3/p/features2image_diffusion/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n\n\n\nimport argtoml\nimport jax\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom pathlib import Path\nfrom typing import Tuple\n\nfrom jaxtyping import Float\nfrom jo3mnist.vis import to_img\nfrom torch.utils.data import DataLoader\n\nfrom features2image_diffusion.__main__ import evaluate\nfrom features2image_diffusion.data import load_mnist_with_features\nfrom features2image_diffusion.unet import load_ddpm\n\nnp.set_printoptions(precision=3)\n\nRUN_PATH = Path.cwd() / \"run/7927ad448cfdb96d1e819f599d5ce8a200a3de67068866289c8cf1e0215ec398\"\nO = argtoml.parse_args(toml_path=RUN_PATH / \"config.toml\")\nRUN = O.run[0]\nDEVICE = \"cuda\"\n\nTRAIN_SET, TEST_SET = load_mnist_with_features(\n    RUN.feature_dir, O.mnist_dir, RUN.batch_size, shuffle=False\n)\n\n/home/jo3/p/features2image_diffusion/.venv/lib/python3.11/site-packages/jo3util/warning.py:18: ToDoWarning: 'Make sure file names are numeric before the .npy.'\n  warnings.warn(msg, ToDoWarning)\n\n\n\ndef all_features_and_labels(dataset: DataLoader) -&gt; Tuple[\n    Float[torch.Tensor, \"datapoints features\"], \n    Float[torch.Tensor, \"datapoints\"]\n]:\n    \"\"\" Gather all features and labels into 2 big numpy arrays.\"\"\"\n    all_features = []\n    all_labels = []\n    for features, _, labels in dataset:\n        all_features.append(torch.Tensor(features))\n        all_labels.append(torch.Tensor(labels))\n    return torch.concatenate(all_features), torch.concatenate(all_labels)\n\nTRAIN_FEATURES, TRAIN_LABELS = all_features_and_labels(TRAIN_SET)\nprint(TRAIN_FEATURES.shape, TRAIN_LABELS.shape) \n\ntorch.Size([60000, 256]) torch.Size([60000])\n\n\n\n#X = np.log(TRAIN_FEATURES + 1e-20)\nTRAIN_FEATURES_AVG = torch.mean(TRAIN_FEATURES, axis=0)\nTRAIN_FEATURES_STD = torch.std(TRAIN_FEATURES, axis=0)\nplt.scatter(\n#plt.errorbar(\n    x=np.arange(TRAIN_FEATURES.shape[1]),\n    y=TRAIN_FEATURES_AVG,\n#    yerr=TRAIN_FEATURES_STD\n)\n\n&lt;matplotlib.collections.PathCollection at 0x7f6ec7bfb5d0&gt;\n\n\n\n\n\nThis does not seem very sparse. Let’s see how sparse an average datapoint is.\n\n@jax.vmap\ndef sparsity(point, thresh=0.01):\n    return np.sum(point &gt; thresh) / len(point)\n\nSPARSITY = sparsity(np.array(TRAIN_FEATURES))\nprint(np.mean(SPARSITY).item(), np.std(SPARSITY).item())\n\nAn NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n\n\n0.5737580060958862 0.0127316415309906\n\n\nMore than half the features are active for any picture. That’s not good, we’ll need to run this again sometime. Let’s sort them by variance so we can guide our edits.\n\nFEATURES_SORTED_BY_STD = np.argsort(TRAIN_FEATURES_STD, axis=0)\nprint(FEATURES_SORTED_BY_STD[-10:])\nprint(TRAIN_FEATURES_AVG[FEATURES_SORTED_BY_STD][-10:])\nprint(TRAIN_FEATURES_STD[FEATURES_SORTED_BY_STD][-10:])\n\ntensor([ 60, 190, 150, 180, 251,  96, 215, 142, 176, 128])\ntensor([3.3336, 2.9315, 2.8921, 2.6445, 2.9475, 3.9932, 2.7286, 2.6410, 3.2082,\n        2.9412])\ntensor([1.5774, 1.5966, 1.6343, 1.6751, 1.7339, 1.7395, 1.7496, 1.7693, 1.7746,\n        1.7810])\n\n\nLet’s now get an example image.\n\ndel TRAIN_FEATURES\ndel TRAIN_LABELS\n\nEXAMPLE = next(iter(TRAIN_SET))\nEXAMPLE_FEATURES = torch.unsqueeze(EXAMPLE[0][0], 0)\nEXAMPLE_IMAGE = EXAMPLE[1][0]\nEXAMPLE_LABEL = EXAMPLE[2][0]\n\nprint(\"class =\", EXAMPLE_LABEL)\nto_img(EXAMPLE_IMAGE)\n\nclass = tensor(5)\n\n\n\n\n\nAnd now we let the ddpm generate variations on this image by conditioning it on the image’s features.\n\nDDPM = load_ddpm(\n    RUN_PATH / \"model/epoch-22.pth\",\n    EXAMPLE_FEATURES.shape[-1],\n    n_T=400,\n    device=DEVICE,\n    opts=RUN\n).eval()\n\n\ndef generate_and_show(\n    ddpm,\n    features,\n    num_generations,\n    original_img=None,\n    device=DEVICE\n):\n    # Generate images.\n    with torch.no_grad():\n        generations, _ = DDPM.sample(\n            features,\n            num_generations,\n            original_img.shape,\n            device\n        )\n    generations = generations.cpu().numpy()\n\n    # Determine the shape of the table of images.\n    num_images = num_generations\n    if original_img is not None:\n        num_images += 1\n    rows = int(np.sqrt(num_images))\n    cols = num_images // rows\n    if rows * cols &lt; num_images:\n        cols += 1\n    fig, axs = plt.subplots(rows, cols, facecolor=\"gray\")\n\n    # Place the images in the table.\n    for i, generation in enumerate(generations):\n        r = i // cols\n        c = i % cols\n        axs[r, c].imshow(to_img(generation))\n        axs[r, c].set_axis_off()\n    if original_img is not None:\n        axs[-1, -1].imshow(to_img(original_img))\n        axs[-1, -1].set_axis_off()\n    plt.show()\n\n    return generations\n\n_ = generate_and_show(DDPM, EXAMPLE_FEATURES, 5, EXAMPLE_IMAGE)\n\n\nsampling timestep 100\n\n\n\n\n\nThose are some crappy generations.\nLet’s see how they change as we change the features. The 128th features had the highest standard deviation, so let’s what it is here, and then change it.\n\nprint(EXAMPLE_FEATURES[0, 128])  # That's close to the average.\n\ndef edit_features(features, value, *index):\n    new_features = features.clone().detach()\n    slice = new_features\n    for i in index[:-1]:\n        slice = slice[i]\n    slice[index[-1]] = value\n    return new_features\n\nEDITED_FEATURES = edit_features(EXAMPLE_FEATURES, 0.0, 0, 128)\n_ = generate_and_show(DDPM, EDITED_FEATURES, 5, EXAMPLE_IMAGE)\n\ntensor(2.8017)\n\nsampling timestep 100"
  },
  {
    "objectID": "look-at-image.html",
    "href": "look-at-image.html",
    "title": "",
    "section": "",
    "text": "import jupyter\nfrom pathlib import Path\nfrom PIL import Image\nimport plotly.express as px\nimport ipywidgets as widgets\n\n%cd ../run/\n\nrun_dir = Path(\"4409b6282a7d05f0b08880228d6d6564011fa40be412073ff05aff8bf2dc49fa\")\ndata_id = 3\nfeature_id = 0\nedit = 0\n\nimage = Image.open(run_dir / str(data_id) / \"unedited-images.png\")\nfig = px.imshow(image)\nfig.show()\n\n/home/jo3/p/features2image_diffusion/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning:\n\nusing dhist requires you to install the `pickleshare` library.\n\n\n\n/home/jo3/p/features2image_diffusion/run\n\n\n\n                                                \n\n\n\nfrom IPython.display import HTML, display\n\nhtml = \"\"\"\n&lt;button id=\"b2\" type=\"button\" onclick='document.getElementById(\"output\").src = \"/run/4409b6282a7d05f0b08880228d6d6564011fa40be412073ff05aff8bf2dc49fa/5/unedited-images.png\"'&gt;\nClick Me!\n&lt;/button&gt;\n\n&lt;img id=\"output\"&gt;&lt;/img&gt;\n\"\"\"\n\ndisplay(HTML(html))\n\n\n\nClick Me!"
  },
  {
    "objectID": "exploratory data analysis.html",
    "href": "exploratory data analysis.html",
    "title": "",
    "section": "",
    "text": "%cd ..\n\n/home/jo3/p/features2image_diffusion\n\n\n/home/jo3/p/features2image_diffusion/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n\n\n\nimport argtoml\nimport jax\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom pathlib import Path\nfrom typing import Tuple\n\nfrom jaxtyping import Float\nfrom jo3mnist.vis import to_img\nfrom torch.utils.data import DataLoader\n\nfrom features2image_diffusion.__main__ import evaluate\nfrom features2image_diffusion.data import load_mnist_with_features, loader_to_dataframe\nfrom features2image_diffusion.unet import load_ddpm\n\nnp.set_printoptions(precision=3)\n\nRUN_PATH = Path.cwd() / \"run/7927ad448cfdb96d1e819f599d5ce8a200a3de67068866289c8cf1e0215ec398\"\nO = argtoml.parse_args(toml_path=RUN_PATH / \"config.toml\")\nRUN = O.run[0]\nDEVICE = \"cuda\"\n\nprint(\"create the dataloader\")\nTRAIN_LOADER, TEST_LOADER = load_mnist_with_features(\n    RUN.feature_dir, O.mnist_dir, RUN.batch_size, shuffle=False\n)\nprint(\"convert the loader to a dataframe\")\nTRAIN_SET = loader_to_dataframe(TRAIN_LOADER, img_dir=\"./res/mnist/img\")\nTRAIN_SET\n\ncreate the dataloader\nconvert the loader to a dataframe\n[1/2] loading labels\n[2/2] loading features\n\n\n/home/jo3/p/features2image_diffusion/.venv/lib/python3.11/site-packages/jo3util/warning.py:18: ToDoWarning: 'Make sure file names are numeric before the .npy.'\n  warnings.warn(msg, ToDoWarning)\n938it [00:15, 60.57it/s]\n100%|██████████| 256/256 [00:00&lt;00:00, 105186.31it/s]\n\n\n\n\n\n\n\n\n\nlabel\nf0\nf1\nf2\nf3\nf4\nf5\nf6\nf7\nf8\n...\nf246\nf247\nf248\nf249\nf250\nf251\nf252\nf253\nf254\nf255\n\n\n\n\n0\n5\n0.0\n0.000000\n0.0\n1.161055\n0.0\n3.392065\n1.578063\n0.0\n0.864978\n...\n0.000000\n1.805129\n0.690105\n0.0\n0.0\n5.241269\n3.842837\n0.176452\n1.565828\n2.654130\n\n\n1\n0\n0.0\n0.000000\n0.0\n0.000000\n0.0\n2.358853\n1.813100\n0.0\n0.979746\n...\n0.000000\n1.363689\n0.324502\n0.0\n0.0\n4.079500\n4.786779\n0.565612\n1.361328\n1.053584\n\n\n2\n4\n0.0\n0.671618\n0.0\n2.503571\n0.0\n2.140285\n2.176373\n0.0\n0.000000\n...\n0.798268\n1.046827\n5.871449\n0.0\n0.0\n3.325204\n0.699517\n1.559370\n0.000000\n0.000000\n\n\n3\n1\n0.0\n1.423953\n0.0\n1.501160\n0.0\n3.335502\n0.000000\n0.0\n0.000000\n...\n0.966482\n0.770367\n3.258740\n0.0\n0.0\n0.427500\n0.728990\n1.242967\n0.000000\n1.957382\n\n\n4\n9\n0.0\n1.553129\n0.0\n1.257297\n0.0\n2.169177\n2.704326\n0.0\n0.000000\n...\n1.234310\n1.416535\n4.576626\n0.0\n0.0\n4.055480\n1.079787\n2.771267\n0.000000\n0.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n59995\n8\n0.0\n1.231961\n0.0\n1.562882\n0.0\n0.851112\n1.040367\n0.0\n0.000000\n...\n0.567958\n0.203369\n2.788358\n0.0\n0.0\n0.652251\n3.938322\n2.780792\n1.568819\n1.649010\n\n\n59996\n3\n0.0\n0.000000\n0.0\n1.200623\n0.0\n1.093581\n0.922486\n0.0\n0.000000\n...\n0.000000\n0.889216\n2.278658\n0.0\n0.0\n2.478583\n3.761220\n1.109611\n1.830709\n2.852156\n\n\n59997\n5\n0.0\n0.000000\n0.0\n1.269054\n0.0\n3.882545\n2.461601\n0.0\n0.414531\n...\n0.000000\n1.437299\n0.571311\n0.0\n0.0\n4.221604\n3.603690\n1.651947\n1.986321\n0.207435\n\n\n59998\n6\n0.0\n0.000000\n0.0\n2.222346\n0.0\n3.886921\n1.917095\n0.0\n0.000000\n...\n0.000000\n1.065447\n2.913041\n0.0\n0.0\n3.674189\n2.821726\n1.130351\n1.015811\n1.842106\n\n\n59999\n8\n0.0\n0.625869\n0.0\n0.752750\n0.0\n1.623499\n2.026078\n0.0\n0.000000\n...\n0.259087\n0.821769\n1.960587\n0.0\n0.0\n2.367158\n4.284012\n2.825384\n1.166023\n0.031489\n\n\n\n\n60000 rows × 257 columns"
  }
]