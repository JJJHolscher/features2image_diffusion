
# training
train			= true
sample			= true
image_dir               = ""
feature_dir		= ""
schedule_sampler        = "uniform"
lr                      = 1e-4
weight_decay            = 0.0
lr_anneal_steps         = 0
batch_size              = 16
microbatch              = -1        # -1 disables microbatches
ema_rate                = "0.9999"  # comma-separated list of EMA values
log_interval            = 10
save_interval           = 10000
resume_checkpoint       = ""
use_fp16                = false
fp16_scale_growth       = 1e-3
clip_denoised		= true
use_ddim		= false
num_samples		= 1e4
model_path		= ""
seed 			= 0

# Unet initialization arguments
[unet]
image_size              = 64
num_channels            = 128
num_res_blocks          = 2
learn_sigma		= false
class_cond              = false
attention_resolutions   = "16,8"
num_heads               = 4
num_heads_upsample      = -1
use_scale_shift_norm    = true
dropout                 = 0.0
seed			= 0

# Diffusion initialization arguments
[diffusion]
steps			= 1000
learn_sigma		= false    # this must be the same as unet.learn_sigma
sigma_small		= false
noise_schedule		= "linear"
use_kl			= false
predict_xstart		= false
rescale_timesteps	= true
rescale_learned_sigmas	= true
timestep_respacing	= ""
